from rag_milvus import tracing
import json
import re


from llama_index.core.llms import ChatMessage, LLM
from llama_index.core.workflow import (
    Event, StartEvent, StopEvent, step,
    Workflow, Context
)
from llama_index.core.agent.workflow import AgentWorkflow
from pyexpat.errors import messages

from tools.calculator import *
from tools.rag_tools import *
from llama_index.core.llms import ChatMessage

from agent_prompts import *
from events import *
from llama_index.utils.workflow import draw_all_possible_flows

class FinancialWorkflow(Workflow):
    def __init__(self, llm: LLM, agents: Dict[str, AgentWorkflow], verbose: bool = False, max_loops:int=3):
        super().__init__(
            timeout=300.0,
            verbose=verbose,
        )

        self.llm = llm
        self.agents = agents
        self.verbose = verbose
        self.max_loops = max_loops
        self.tools = {
            "Calculator": [
                return_rate_tool,
                volatility_tool
            ],
            "DocumentSearch": [custom_vector_rag_tool],
            "KnowledgeGraph": [custom_graph_rag_tool],
        }

    def _extract_json_from_response(self, response_content: str) -> str:
        """
        ä¸€ä¸ªå¥å£®çš„è¾…åŠ©å‡½æ•°ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä» LLM çš„å“åº”ä¸­æå–å‡º JSON å­—ç¬¦ä¸²ã€‚
        """
        # æ­£åˆ™è¡¨è¾¾å¼ï¼šåŒ¹é…ä»ç¬¬ä¸€ä¸ª '{' åˆ°æœ€åä¸€ä¸ª '}' ä¹‹é—´çš„æ‰€æœ‰å†…å®¹
        # re.DOTALL æ ‡å¿—è®© '.' å¯ä»¥åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„ä»»ä½•å­—ç¬¦
        json_match = re.search(r'\{.*\}', response_content, re.DOTALL)

        if json_match:
            json_str = json_match.group(0)
            if self.verbose: print(f"--- [JSON Extractor]: æˆåŠŸæå–åˆ° JSON: '{json_str}' ---")
            return json_str
        else:
            if self.verbose: print(f"--- [JSON Extractor]: æœªåœ¨å“åº”ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„ JSON å¯¹è±¡ã€‚ ---")
            raise ValueError("No valid JSON object found in LLM response.")

    async def _execute_tool_calling_step(self, tool_category: str, user_input: str) -> str:
        """ä¸€ä¸ªé€šç”¨çš„ã€æ‰§è¡Œ Tool Calling çš„è¾…åŠ©å‡½æ•°"""
        target_tools = self.tools[tool_category]
        if self.verbose: print(f"--- [{tool_category}]: æ¥æ”¶åˆ°ä»»åŠ¡ '{user_input}' ---")

        # é˜¶æ®µ 1: æ¨¡å‹å†³ç­–
        response = await self.llm.achat(
            messages=[ChatMessage(role="user", content=user_input)],
            tools=target_tools,
            tool_choice="auto",
        )

        tool_calls = response.message.additional_kwargs.get("tool_calls")

        if not tool_calls:
            if self.verbose: print(f"--- [{tool_category}]: LLM å†³å®šä¸è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å›ç­”ã€‚---")
            return response.message.content

        # é˜¶æ®µ 2: æœ¬åœ°æ‰§è¡Œ
        if self.verbose: print(f"--- ğŸ”§ [{tool_category}]: LLM å†³å®šè°ƒç”¨å·¥å…·... ---")
        tool_outputs = []
        for call in tool_calls:
            tool_name = call.get("function", {}).get("name")
            arguments_str = call.get("function", {}).get("arguments")

            if not tool_name or arguments_str is None:
                tool_outputs.append({"output": f"é”™è¯¯: LLM è¿”å›çš„ tool_call æ ¼å¼ä¸å®Œæ•´: {call}"})
                continue
            arguments = json.loads(arguments_str)

            target_tool = next((t for t in target_tools if t.metadata.name == tool_name), None)
            if not target_tool:
                tool_outputs.append({"output": f"é”™è¯¯: æ‰¾ä¸åˆ°åä¸º '{tool_name}' çš„å·¥å…·å¯¹è±¡"})
                continue

            target_tool_fn = target_tool.fn

            #   æˆ‘ä»¬ç°åœ¨è¦åˆ¤æ–­ target_tool_fn æ˜¯åŒæ­¥è¿˜æ˜¯å¼‚æ­¥
            if asyncio.iscoroutinefunction(target_tool_fn):
                # å¦‚æœæ˜¯å¼‚æ­¥å‡½æ•° (async def)ï¼Œå°±ç›´æ¥ await
                if self.verbose: print(f"      - (Async) æ‰§è¡Œå‡½æ•°: {tool_name}(**{arguments})")
                tool_result = await target_tool_fn(**arguments)
            else:
                # å¦‚æœæ˜¯åŒæ­¥å‡½æ•° (def)ï¼Œå°±ç”¨ asyncio.to_thread åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œ
                if self.verbose: print(f"      - (Sync via Thread) æ‰§è¡Œå‡½æ•°: {tool_name}(**{arguments})")
                tool_result = await asyncio.to_thread(target_tool_fn, **arguments)

            tool_outputs.append({"tool_name": tool_name, "output": str(tool_result)})


        final_result = "\n".join([f"{r['tool_name']} è¿”å›: {r['output']}" for r in tool_outputs])
        return final_result
    # æ­¥éª¤ 1: è§„åˆ’ (Plan)
    @step
    async def dispatcher_step(self, ev: UserInputEvent) -> RAGTriggerEvent | SimpleChatTriggerEvent:
        if self.verbose: print(f"--- [Dispatcher]: åˆ†æè¯·æ±‚ '{ev.user_msg}'... ---")
        prompt = DISPATCHER_PROMPT.format(user_msg=ev.user_msg, chat_history=str(ev.chat_history))
        response = await self.llm.achat([ChatMessage(role="user", content=prompt)])
        try:
            raw_content = response.message.content or ""
            if self.verbose: print(f"--- [Dispatcher]: LLM è¿”å›çš„åŸå§‹å†³ç­–æ–‡æœ¬: '{raw_content}' ---")

            cleaned_response = self._extract_json_from_response(raw_content)
            decision = json.loads(cleaned_response)

            if decision.get("task_type") == "retrieval":

                return RAGTriggerEvent(user_msg=ev.user_msg, query=ev.user_msg)
            else:
                return SimpleChatTriggerEvent(user_msg=ev.user_msg)
        except Exception as e:
            if self.verbose: print(f"--- [Dispatcher]: å†³ç­–è§£æå¤±è´¥ ({e})ï¼Œè½¬ä¸ºç®€å•èŠå¤©ã€‚ ---")
            return SimpleChatTriggerEvent(user_msg=ev.user_msg)

    # --- è·¯çº¿ A: ç®€å•èŠå¤© ---
    @step
    async def simple_chat_step(self, ev: SimpleChatTriggerEvent) -> FinalOutputEvent:
        if self.verbose: print(f"--- [SimpleChat]: ç›´æ¥å›ç­”... ---")
        response = await self.llm.achat([ChatMessage(role="user", content=ev.user_msg)])
        return FinalOutputEvent(response=response.message.content)

    # --- è·¯çº¿ B: RAG æµç¨‹ ---

    # æ­¥éª¤ B.1: å¹¶è¡Œæ£€ç´¢ (Fan-Out)
    @step
    async def milvus_retrieval_step(self, ev: RAGTriggerEvent) -> SearchResultEvent:
        if self.verbose: print(f"--- [Milvus]: (å¾ªç¯ {ev.current_loop}) å¼€å§‹å¹¶è¡Œæ£€ç´¢... ---")
        nodes = await custom_milvus_search(ev.query)
        return SearchResultEvent(source="milvus", results=nodes, user_msg=ev.user_msg, query=ev.query,
                                 current_loop=ev.current_loop)

    @step
    async def graph_retrieval_step(self, ev: RAGTriggerEvent) -> SearchResultEvent:
        if self.verbose: print(f"--- [Graph]: (å¾ªç¯ {ev.current_loop}) å¼€å§‹å¹¶è¡ŒæŸ¥è¯¢... ---")
        nodes = await asyncio.to_thread(custom_graph_search, ev.query)
        return SearchResultEvent(source="rag_graph", results=nodes, user_msg=ev.user_msg, query=ev.query,
                                 current_loop=ev.current_loop)


    @step
    async def aggregator_step(self, ev: SearchResultEvent, ctx: Context) -> AggregatedContextEvent| None:

        search_results: List[SearchResultEvent] | None = ctx.collect_events(
            ev, expected=[SearchResultEvent, SearchResultEvent]
        )
        if search_results is None:
            # å¦‚æœè¿˜æ²¡æœ‰æ”¶é›†é½ï¼ˆæ¯”å¦‚åªæœ‰ä¸€ä¸ªåˆ†æ”¯å®Œæˆäº†ï¼‰ï¼Œ
            # å°±è¿”å› Noneï¼Œå·¥ä½œæµä¼šæš‚åœæ­¤æ­¥éª¤å¹¶ç­‰å¾…ä¸‹ä¸€ä¸ªäº‹ä»¶
            if self.verbose: print(f"--- [Aggregator]: å·²æ”¶åˆ°æ¥è‡ª '{ev.source}' çš„ç»“æœï¼Œç­‰å¾…å…¶ä»–å¹¶è¡Œç»“æœ... ---")
            return None
        if self.verbose: print(f"--- [Aggregator]: å¼€å§‹èåˆå»é‡... ---")

        all_nodes = []
        for result_event in search_results:
            all_nodes.extend(result_event.results)

        # (å»é‡é€»è¾‘)
        unique_nodes = {(n.node.metadata.get("file_name"), n.node.get_content()): n for n in all_nodes}
        final_nodes = list(unique_nodes.values())

        fused_context = "\n\n".join(
            [f"æ¥æº: {n.node.metadata.get('file_name', 'N/A')}\nå†…å®¹: {n.node.get_content()}" for n in final_nodes])
        ref_event = search_results[0]

        return AggregatedContextEvent(
            user_msg=ref_event.user_msg, query=ref_event.query, current_loop=ref_event.current_loop,
            retrieved_nodes=final_nodes, fused_context=fused_context
        )

    # æ­¥éª¤ B.3: åˆ¤æ–­æ˜¯å¦éœ€è¦è®¡ç®—
    @step
    async def calculation_check_step(self, ev: AggregatedContextEvent) -> CalculationEvent | SummarizationEvent:
        if self.verbose: print(f"--- [CalcCheck]: æ£€æŸ¥æ˜¯å¦éœ€è¦è®¡ç®—... ---")
        prompt = CALCULATION_CHECK_PROMPT.format(user_msg=ev.user_msg, context=ev.fused_context)
        response = await self.llm.achat([ChatMessage(role="user", content=prompt)])
        raw_content = response.message.content or ""
        if self.verbose: print(f"--- [Dispatcher]: LLM è¿”å›çš„åŸå§‹å†³ç­–æ–‡æœ¬: '{raw_content}' ---")

        cleaned_response = self._extract_json_from_response(raw_content)
        decision = json.loads(cleaned_response)

        if decision.get("calculation_needed"):
            if self.verbose: print(f"--- [CalcCheck]: éœ€è¦è®¡ç®—ã€‚è¿›å…¥è®¡ç®—æ­¥éª¤... ---")
            # å°†æ‰€æœ‰çŠ¶æ€ä¼ é€’ç»™è®¡ç®—äº‹ä»¶
            return CalculationEvent(user_msg=ev.user_msg, calculation_details=decision.get("calculation_query"),
                                    fused_context=ev.fused_context,current_loop=ev.current_loop)
        else:
            if self.verbose: print(f"--- [CalcCheck]: æ— éœ€è®¡ç®—ã€‚ç›´æ¥è¿›å…¥æ€»ç»“æ­¥éª¤... ---")
            # å¦‚æœä¸éœ€è¦è®¡ç®—ï¼Œå°±ç›´æ¥ç”¨èåˆçš„ä¸Šä¸‹æ–‡å»ç”Ÿæˆç­”æ¡ˆ
            return SummarizationEvent(user_msg=ev.user_msg, final_context=ev.fused_context,current_loop=ev.current_loop)

    # æ­¥éª¤ B.4: è®¡ç®— (å¯é€‰è·¯å¾„)
    @step
    async def calculation_step(self, ev: CalculationEvent) -> SummarizationEvent:
        if self.verbose: print(f"--- [Calculator]: æ‰§è¡Œè®¡ç®—... ---")
        # (ä½ éœ€è¦ä¸€ä¸ª _execute_tool_calling_step è¾…åŠ©å‡½æ•°)
        calc_result = await self._execute_tool_calling_step("Calculator", ev.calculation_details)

        final_context = f"æ£€ç´¢åˆ°çš„ä¿¡æ¯:\n{ev.fused_context}\n\nè®¡ç®—ç»“æœ:\n{calc_result}"
        return SummarizationEvent(user_msg=ev.user_msg, final_context=final_context, current_loop=ev.current_loop)

    # æ­¥éª¤ B.5: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    @step
    async def summarizer_step(self, ev: SummarizationEvent) -> CritiqueEvent:
        if self.verbose: print(f"---  [Summarizer]: ç”Ÿæˆè‰ç¨¿å›ç­”... ---")
        prompt = SUMMARIZER_PROMPT.format(context=ev.final_context, user_msg=ev.user_msg)
        response = await self.llm.achat([ChatMessage(role="user", content=prompt)])
        draft_answer = response.message.content
        return CritiqueEvent(user_msg=ev.user_msg, final_context=ev.final_context, preliminary_answer=draft_answer,
                             current_loop=ev.current_loop)

    # æ­¥éª¤ B.6: è´¨é‡è¯„ä¼°ä¸å¾ªç¯
    @step
    async def quality_check_step(self, ev: CritiqueEvent) -> RAGTriggerEvent | FinalOutputEvent:
        if self.verbose: print(f"--- [Critique]: è¯„ä¼°è‰ç¨¿å›ç­”... ---")
        prompt = CRITIQUE_PROMPT.format(user_msg=ev.user_msg, draft_answer=ev.preliminary_answer)
        response = await self.llm.achat([ChatMessage(role="user", content=prompt)])
        raw_content = response.message.content or ""
        if self.verbose: print(f"--- [Dispatcher]: LLM è¿”å›çš„åŸå§‹å†³ç­–æ–‡æœ¬: '{raw_content}' ---")

        cleaned_response = self._extract_json_from_response(raw_content)
        critique = json.loads(cleaned_response)

        current_loop = ev.current_loop if hasattr(ev, 'current_loop') else 1

        if critique.get("is_sufficient") or current_loop >= self.max_loops:
            if not critique.get("is_sufficient"):
                print(f"---  [Critique]: å·²è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•° ({self.max_loops})ï¼Œå¼ºåˆ¶ç»“æŸã€‚---")
            if self.verbose: print(f"--- [Critique]: å›ç­”ä»¤äººæ»¡æ„ã€‚å·¥ä½œæµç»“æŸã€‚ ---")
            return FinalOutputEvent(response=ev.preliminary_answer)
        else:
            if self.verbose: print(f"--- [Critique]: å›ç­”ä¸ç†æƒ³ã€‚å°†åŸºäºä¿®æ­£å»ºè®®é‡æ–°å¼€å§‹æ£€ç´¢... ---")
            new_query = f"åŸå§‹é—®é¢˜: {ev.user_msg}\nä¿®æ­£å»ºè®®: {critique.get('missing_information')}"
            return RAGTriggerEvent(user_msg=ev.user_msg, query=new_query, current_loop=current_loop + 1)


draw_all_possible_flows(FinancialWorkflow, filename="multi_step_workflow.html")